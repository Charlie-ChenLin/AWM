# Reply (1/3)
We thank the reviewer for their thoughtful and positive assessment of our work, including AWM's computational efficiency, robustness, zero influence on model performance and near-zero false positive rates. Below, we address each of the reviewer’s points one by one.

> **[W1&Q1]** AWM relies on a shared vocabulary and token embedding overlaps. Thus, it is vulnerable to the cases where the early blocks of the model is replaced, or the tokenizer is replaced or retrained.

We respectfully believe that AWM is more robust than this concern suggests, as detailed below.
- First, although one can in principle heavily modify or replace the **early layers** of an LLM, **prior work [1] shows that such interventions typically cause large performance drops that are hard to recover even with further training**. This conflicts with the usual goal of reusing a strong base model.

- Second, **AWM is applicable to the case where the tokenizer is replaced or retrained**. By noticing the public discussion around some certain MoE model and Qwen-2.5-14B, which only share roughly 21% of vocabulary tokens, we apply AWM to detect similarity of the two, and report a similarity score of 69.95%, and an absolute Z-score of 248.48. This result suggests that even though the tokenizer is heavily replaced or retrained, AWM can remain effective.

- Last, **AWM does not rely heavily on the overlap of tokens**. We run experiments for all scenarios in Table 2 with varying numbers of shared tokens, and report the average absolute Z-score for each scenario in Appendix G.1. The results suggest that AWM remain effective and maintain high average absolute Z-scores (>100) in most cases even if there are very limited overlapping tokens (~100 tokens) in the vocabulary. We summarize the results in the following table.

|Method|10|100|500|1000|3000|5000|10000|
|-|-|-|-|-|-|-|-|
|SFT|354.32|354.32|354.32|354.32|354.32|354.32|354.32|
|Continual Pretrain|5.40|147.64|192.08|204.63|208.02|208.21|210.89|
|Upcycling|44.22|248.28|267.94|275.18|281.71|286.05|287.85|
|Multi modal|205.50|332.80|334.52|334.81|334.82|334.82|334.78|
|RL|355.79|355.79|355.79|355.79|355.79|355.79|355.79|
|Pruning|76.46|250.94|255.51|255.87|255.93|256.06|257.72|

Reference
[1] Huang, Hanbo, et al. "Archilles' Heel in Semi-open LLMs: Hiding Bottom against Recovery Attacks." (2024).


> **[W2&Q2]** AWM may fail to detect API-based distillation. Any insights on piracy cases involving knowledge distillation? Could lightweight black-box probes be combined with AWM to first flag potential distillation cases? 

We appreciate the reviewer’s careful consideration of our work. 
- First, **AWM is explicitly designed for the white-box setting where one suspects that a model directly or indirectly inherits weights from a base model** (see Section 4.1). In this regime, weight-matrix similarity is the right signal to examine, and our experiments show that AWM can offer high confidence with a very low false-positive rate. In contrast, in pure API-based knowledge distillation the student can mimic the teacher’s behaviour while having almost uncorrelated weights, so weight-based fingerprint, including ours, has limited power. We therefore view such API-only distillation cases as primarily the domain of black-box fingerprinting methods, rather than the main target of AWM.

- Second, **black-box and white-box approaches are complementary rather than competing**.  Since AWM and black-box methods detect matrix weight similarity and output similarity respectively, combining the two approaches can yield a conclusion on the independency of both the model weights and the data used in training.

- Finally, **AWM’s accuracy and strict control of false positives make it well suited for third-party verification scenarios**, where model owners, regulators, or courts can confidentially submit model weights to an independent auditor. In such settings, AWM can provide strong evidence about whether one model’s weights are independently trained or derived from another, naturally complementing black-box tests that focus on behavioural similarity and potential API-based distillation.


# Reply (2/3)

> **[W3&Q3]** Will AWM work when the architecture undergoes significant depth/width changes, layer removal, layer addition, cross-layer sharing, or reordering of blocks?

We show that AWM remains effective under these architectural modifications, as detailed below.
- First, **layer removal/layer addition/layer reordering/cross-layer sharing can be effectively detected by AWM** since Algorithm 1 can find an optimal match of layers by performing LAP on layer-wise similarities.  Empirically, we find that
    - The detection of **layer removal** is effective. In the "pruning" part of Table 2, models including Sheared-LLaMA have gone through layer removal, but still presents a high similarity to the base models under AWM detection (most showing absolute Z-scores higher than 200).
    - AWM successfully flags **layer addition**.  We additionally collect 3 model pairs within this case. Moreover, we also train an additional LLaMA-3.2-3B-two-layer by adding two radomly initialized layers to LLaMA-3.2-3B and training on 6B tokens in SlimPajama dataset to support this viewpoint. In all the four cases AWM remains effective as well, and the results are summarized in the table below.
    - For **layer reordering** and **cross-layer sharing**, **the case is similar theoretically**. Though we do not find examples of such cases, LAP over layer-wise similarities in Algorithm 1 can figure out layer pairs as layer removal and layer addition since the computation of layer-wise similarities is identical.

Method|Model Pair|Absolute Z-Score
|-|-|-|
Add layers|SOLAR-10.7B-v1.0 vs Mistral-7B-v0.1|323.5893
||Yi-9B vs Yi-6B|329.5536
||Llama2-7b vs LLaMA-Pro-8B|355.8036
||LLaMA-3.2-8B-two-layers vs LLaMA-3.2-8B|355.1

- Second, **AWM still works in cases where the width of the layers changes**. As discussed in  "Robust Recovery of Weight Similarities" in Section 5, width changes, especially pruning, can be viewed as a semi-orthogonal transformation which can be tolerated by UCKA to some extent. The results in the "Pruning" part of Table 2 further validate this point: though many pairs (e.g. LLaMA3-8B vs LLaMA3-3B) have gone through significant width pruning, AWM still successfully flags the similarity. 

> **[W4&Q4]** AWM is very simple and is relatively easy to attack. 

The simple design of AWM requires minimum additional parameters, from which AWM's robustness benefits (see "Robust Recovery of Weight Similarities" in Section 5). Compared to the baselines (HuRef, REEF, Intrinsic Fingerprint), **our approach is the state-of-the-art in terms of robustness, a result of the simple yet effective design**. Moreover, AWM is built upon a systematic analysis of matrix weight manipulations in Section 4. **A variety of attacks, including signature matrices, permutations, constant scaling and orthogonal transformations (see Section 4.5), are fully detectable with AWM**  due to the properties of UCKA (see "Central Kernel Alignment (CKA)" in Section 3) and LAP reconstruction of the permutation attacks. Moreover, the LAP matching of layers in Algorithm 1 also prevents layer-wise attacks, as discussed in previous responses. Hence, AWM is a simple detection method but robust to various forms of attacks. 

> **[W5&Q5]** Will AWM work if one model is fused from multiple sources?

We agree that mixed-origin and merged models are an important use case. Our current formulation of AWM is pairwise and evaluates similarity between one suspect model and one candidate source, but this does not preclude handling multi-source merges. In fact, for publicly documented merged models such as mergekit-community/Qwen3-1.5B-Instruct (a TIES merge of several Qwen2.5-1.5B variants) and SakanaAI/EvoLLM-JP-v1-7B (an evolutionary merge of multiple 7B models), we apply AWM separately between the merged model and each of its published base models. **We find that AWM assigns consistently high similarity scores to the true source models, allowing us to recover which components were used in the merge**. Results are shown in the following table.

|Offspring Model|mergekit-community/Qwen3-1.5B-Instruct|||SakanaAI/EvoLLM-JP-v1-7B|||
|-|-|-|-|-|-|-|
|Source Model|Qwen2.5-1.5B-Instruct|Qwen2.5-Math-1.5B-Instruct|Qwen2.5-Coder-1.5B-Instruct|shisa-gamma-7b-v1|WizardMath-7B-V1.1|Abel-7B-002|
|Absolute Z-Score|84.2679|274.4107|144.6964|353.0179|351.5536|351.5179|


# Reply (3/3)

> **[W6&Q7]** Why no baselines like PCS and ICS? Add comparison methods and explicit ablation experiments.

PCS and ICS are both proposed in HuRef, where ICS is more robust than PCS as suggested in HuRef. Therefore, we choose ICS as HuRef's baseline. Besides, we add Intrinsic Fingerprint [1] and PCS as additional baselines in Table 3, which are still outperformed by AWM. We also present them in the following table along with the performance of our method:

|Method|Metric|SFT|CPT|UP|MM|RL|PR|All|
|-|-|-|-|-|-|-|-|-|
|Intrinsic Fingerprint|\|Z\| ↑|1.535|1.193|1.408|1.532|1.542|1.141|1.392|
|Intrinsic Fingerprint|AUC ↑|1.000|0.896|0.969|1.000|1.000|0.876|0.957|
|Intrinsic Fingerprint|pAUC ↑|1.000|0.422|0.800|1.000|1.000|0.400|0.770|
|Intrinsic Fingerprint|TPR@1%FPR ↑|1.000|0.300|0.800|1.000|1.000|0.400|0.750|
|PCS|\|Z\| ↑|73.786|74.650|0.727|14.950|163.399|17.226|57.457|
|PCS|AUC ↑|0.958|0.959|0.791|0.802|0.984|0.666|0.860|
|PCS|pAUC ↑|0.656|0.600|0.078|0.500|0.900|0.100|0.472|
|PCS|TPR@1%FPR ↑|0.500|0.600|0.000|0.500|0.900|0.100|0.433|
|Ours|\|Z\| ↑|353.788|219.155|287.634|334.556|355.250|267.233|302.936|
|Ours|AUC ↑|1.000|1.000|1.000|1.000|1.000|1.000|1.000|
|Ours|pAUC ↑|1.000|1.000|1.000|1.000|1.000|1.000|1.000|
|Ours|TPR@1%FPR ↑|1.000|1.000|1.000|1.000|1.000|1.000|1.000|


Moreover, we conduct an ablation study on  mechanisms of AWM, including CKA kernel selection (linear/rbf) and the unbiased/biased design of CKA, and summarize the average absolute Z-scores in the scenarios of Table 2 in Appendix G.2. We also present these results here:

|CKA Design|Linear (Unbiased)|Linear (Biased)|RBF (Unbiased)|RBF (Biased)|
|-|-|-|-|-|
|SFT|356.0223|18.3099|527.3949|11.5843|
|Continual Pretrain|217.5003|11.2954|320.9173|7.0701|
|Upcycling|291.6191|15.1994|432.1476|9.6776|
|Multi Modal|336.6757|17.3766|498.8918|11.0056|
|RL|357.5001|18.3850|529.6448|11.6330|
|Pruning|268.9175|13.8985|394.8391|8.7331|

In addition, we perform an ablation study on the number of overlapped tokens used, and the results are shown in Appendix G.1 and the response to W1&Q1.  The results suggest that AWM can effectively detect model similarities even if the number of shared vocabulary tokens is extremely low (~100 tokens).

References
[1] Yoon, Do-hyeon, et al. "Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!." arXiv preprint arXiv:2507.03014 (2025).

> **[W7]** Add discussions on black-box methods in Related Works.

Thank you for pointing this out! We've revised the paper accordingly and added the discussion of black-box approaches in Related Works. 

> **[Q6]** Release an evaluation sheet (model names/versions, checkpoints, tokenizer specs, training corpus tags), and precise CKA/LAP implementation details (module selection, sampling of parameter blocks, normalization, kernel choices). 

- We have added a comprehensive evaluation sheet in Appendix F (Table 4). This table details the 60 offspring models used in our study, mapping each abbreviation to its full model name, base model, and relevant training corpus. To facilitate reproducibility, every entry in the “Full Model Name” column is hyperlinked directly to the corresponding official model checkpoint on the Hugging Face Hub.
- As for implementation details, we employ the Linear Kernel ($k(X, Y) = XY^\top$) for Centered Kernel Alignment (CKA) due to its computational efficiency. To mitigate the finite-sample bias inherent in standard HSIC estimations, we utilize the Unbiased CKA (UCKA) estimator. As for module selection, our method operates on two specific sets of weights: first, we utilize the intersection of the word embeddings ($W_{emb}$) to solve the Linear Assignment Problem (LAP), allowing us to accurately recover the permutation ($P$) and signature ($D$) matrices; second, we compute the final fingerprinting scores using the Query ($W_Q$) and Key ($W_K$) weights, as their transformations are strictly constrained.
- To address structural discrepancies such as differing layer counts, we identify the optimal layer correspondence by maximizing the total similarity; specifically, we solve the assignment problem on a cost matrix constructed from the pairwise UCKA scores of $W_Q$ and $W_K$ between all source and target layers.




